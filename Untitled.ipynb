{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "855330dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement cPickle (from versions: none)\n",
      "ERROR: No matching distribution found for cPickle\n"
     ]
    }
   ],
   "source": [
    "!pip install cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1168f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cPickle\n",
    "import os\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# with open(\"cifar-10/data_batch_1\", 'rb') as fo: # load CIFAR-10 dataset\n",
    "#     dict = cPickle.load(fo)\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "# load dataset keras will download cifar-10 datset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()  \n",
    "\n",
    "y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# labels = np.asarray(dict[\"labels\"]).reshape((10000,1))\n",
    "# labels = np.where(labels==3, 1, 0).T # for cat image, assign 1, non cat image assign 0\n",
    "\n",
    "# data = dict[\"data\"].T\n",
    "\n",
    "# train_set_x = data[:,:7000]\n",
    "# train_set_y = labels[:,:7000]\n",
    "# test_set_x = data[:,7000:]\n",
    "# test_set_y = labels[:,7000:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4567d9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 train samples\n",
      "10000 test samples\n",
      "(50000, 3072) train shape\n",
      "(10000, 3072) test shape\n",
      "(500000,) train shape\n",
      "(100000,) test shape\n"
     ]
    }
   ],
   "source": [
    "# Converting the 50000 , 32*32*3 images into 50000 * 3072 arrays\n",
    "x_train = x_train.reshape(50000, 3072)\n",
    "x_test = x_test.reshape(10000, 3072)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "y_train = y_train.flatten()\n",
    "y_test = y_test.flatten()\n",
    "\n",
    "# normalize the datasets\n",
    "x_train /= 255.\n",
    "x_test /= 255.\n",
    "\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print(x_train.shape , \"train shape\")\n",
    "print(x_test.shape , \"test shape\")\n",
    "print(y_train.shape , \"train shape\")\n",
    "print(y_test.shape , \"test shape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "beaa2eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x_train.shape)\n",
    "# print(y_train.shape)\n",
    "# print(x_test.shape)\n",
    "# print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1f7b000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "\n",
    "    s = 1/(1+np.exp(-1*z))\n",
    "    return s\n",
    "\n",
    "\n",
    "# initialize and zero w and b\n",
    "def initialize_with_zeros(dim):\n",
    "\n",
    "    w = np.zeros((dim,1))\n",
    "    b = 0\n",
    "\n",
    "    assert(w.shape == (dim, 1))\n",
    "    assert(isinstance(b, float) or isinstance(b, int))\n",
    "\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5d02916",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate cost and gradients\n",
    "def propagate(w, b, X, Y):\n",
    "\n",
    "    m = X.shape[1]\n",
    "\n",
    "    A = sigmoid(np.dot(w.T,X)+b)\n",
    "    cost = np.sum(Y*np.log(A)+((1-Y)*np.log(1-A)))/-m\n",
    "\n",
    "    dw = np.dot(X,(A-Y).T)/m\n",
    "    db = (np.sum(A-Y))/m\n",
    "\n",
    "    assert(dw.shape == w.shape)\n",
    "    assert(db.dtype == float)\n",
    "    cost = np.squeeze(cost)\n",
    "    assert(cost.shape == ())\n",
    "\n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "\n",
    "    return grads, cost\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4f9b23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iteratea and optize weights and bias\n",
    "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):\n",
    "\n",
    "    costs = []\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "\n",
    "        grads, cost = propagate(w, b, X, Y)\n",
    "\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "\n",
    "        w -= learning_rate*dw\n",
    "        b -= learning_rate*db\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "\n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "\n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "\n",
    "    return params, grads, costs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16f577d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predtic if image is cat or non cat using logistic regression and optimized values for w and b\n",
    "def predict(w, b, X):\n",
    "\n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1,m))\n",
    "    w = w.reshape(X.shape[0], 1)\n",
    "    A = sigmoid(np.dot(w.T,X)+b)\n",
    "\n",
    "    for i in range(A.shape[1]):\n",
    "\n",
    "\n",
    "        if A[0,i] < 0.5:\n",
    "            Y_prediction[0,i]=0\n",
    "        elif A[0,i]>0.5:\n",
    "            Y_prediction[0,i]=1\n",
    "        pass\n",
    "\n",
    "    assert(Y_prediction.shape == (1, m))\n",
    "\n",
    "    return Y_prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc9c8dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine everything to form logistic regression model\n",
    "def model(X_train, Y_train, X_test, Y_test, num_iterations = 1000, learning_rate = 0.5, print_cost = True):\n",
    "\n",
    "    w, b = initialize_with_zeros(32*32*3)\n",
    "\n",
    "    parameters, grads, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost = False)\n",
    "\n",
    "    w = parameters[\"w\"]\n",
    "    b = parameters[\"b\"]\n",
    "\n",
    "    Y_prediction_test = predict(w, b, X_test)\n",
    "    Y_prediction_train = predict(w, b, X_train)\n",
    "\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
    "\n",
    "    d = {\"costs\": costs,\n",
    "         \"Y_prediction_test\": Y_prediction_test,\n",
    "         \"Y_prediction_train\" : Y_prediction_train,\n",
    "         \"w\" : w,\n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "\n",
    "    return d\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1500897d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (1,3072) and (50000,3072) not aligned: 3072 (dim 1) != 50000 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1136\\1005007121.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.005\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#plot learning curve\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcosts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'costs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcosts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1136\\1180058887.py\u001b[0m in \u001b[0;36mmodel\u001b[1;34m(X_train, Y_train, X_test, Y_test, num_iterations, learning_rate, print_cost)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitialize_with_zeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcosts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"w\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1136\\2129285899.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(w, b, X, Y, num_iterations, learning_rate, print_cost)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpropagate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mdw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"dw\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1136\\3681364912.py\u001b[0m in \u001b[0;36mpropagate\u001b[1;34m(w, b, X, Y)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\overrides.py\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (1,3072) and (50000,3072) not aligned: 3072 (dim 1) != 50000 (dim 0)"
     ]
    }
   ],
   "source": [
    "d = model(x_train, y_train, x_test, y_test, num_iterations = 2000, learning_rate = 0.005, print_cost = True)\n",
    "\n",
    "#plot learning curve\n",
    "costs = np.squeeze(d['costs'])\n",
    "plt.plot(costs)\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (per hundreds)')\n",
    "plt.title(\"Learning rate =\" + str(d[\"learning_rate\"]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39edcf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1041e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57addbaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:126: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "<>:126: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train image shape:    (49000, 32, 32, 3)\n",
      "Train label shape:    (49000,)\n",
      "Validate image shape: (1000, 32, 32, 3)\n",
      "Validate label shape: (1000,)\n",
      "Test image shape:     (10000, 32, 32, 3)\n",
      "Test label shape:     (10000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "C:\\Users\\aish0\\AppData\\Local\\Temp\\ipykernel_1136\\1705125735.py:126: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if verbose and i % 100 == 0 and len(lossHistory) is not 0:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training Svm classifier\n",
      "Loop 0 loss 154260.67999404832\n",
      "Loop 100 loss 20659.177451787145\n",
      "Loop 200 loss 2769.3138368737864\n",
      "Loop 300 loss 375.07264514125865\n",
      "Loop 400 loss 53.86715800676492\n",
      "Loop 500 loss 12.020435810897313\n",
      "Loop 600 loss 6.106158466296016\n",
      "Loop 700 loss 6.248912508612036\n",
      "Loop 800 loss 5.850389331128758\n",
      "Loop 900 loss 5.684072264174233\n",
      "Loop 1000 loss 5.204298315363758\n",
      "Loop 1100 loss 5.928789500208665\n",
      "Loop 1200 loss 5.305975910811904\n",
      "Loop 1300 loss 5.322091061880503\n",
      "Loop 1400 loss 5.476947835876593\n",
      "Training time: 19.007946968078613\n",
      "Training acc:   35.52448979591837%\n",
      "Validating acc: 34.5%\n",
      "Testing acc:    35.31%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Library for plot the output and save to file\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the CIFAR10 dataset\n",
    "from keras.datasets import cifar10\n",
    "baseDir = os.path.dirname(os.path.abspath('__file__')) + '/'\n",
    "classesName = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "(xTrain, yTrain), (xTest, yTest) = cifar10.load_data()\n",
    "xVal = xTrain[49000:, :].astype(float)\n",
    "yVal = np.squeeze(yTrain[49000:, :])\n",
    "xTrain = xTrain[:49000, :].astype(float)\n",
    "yTrain = np.squeeze(yTrain[:49000, :])\n",
    "yTest = np.squeeze(yTest)\n",
    "xTest = xTest.astype(float)\n",
    "\n",
    "# Show dimension for each variable\n",
    "print ('Train image shape:    {0}'.format(xTrain.shape))\n",
    "print ('Train label shape:    {0}'.format(yTrain.shape))\n",
    "print ('Validate image shape: {0}'.format(xVal.shape))\n",
    "print ('Validate label shape: {0}'.format(yVal.shape))\n",
    "print ('Test image shape:     {0}'.format(xTest.shape))\n",
    "print ('Test label shape:     {0}'.format(yTest.shape))\n",
    "\n",
    "# Show some CIFAR10 images\n",
    "plt.subplot(221)\n",
    "plt.imshow(xTrain[0])\n",
    "plt.axis('off')\n",
    "plt.title(classesName[yTrain[0]])\n",
    "plt.subplot(222)\n",
    "plt.imshow(xTrain[1])\n",
    "plt.axis('off')\n",
    "plt.title(classesName[yTrain[1]])\n",
    "plt.subplot(223)\n",
    "plt.imshow(xVal[0])\n",
    "plt.axis('off')\n",
    "plt.title(classesName[yVal[1]])\n",
    "plt.subplot(224)\n",
    "plt.imshow(xTest[0])\n",
    "plt.axis('off')\n",
    "plt.title(classesName[yTest[0]])\n",
    "plt.clf()\n",
    "\n",
    "# Pre processing data\n",
    "# Normalize the data by subtract the mean image\n",
    "meanImage = np.mean(xTrain, axis=0)\n",
    "xTrain -= meanImage\n",
    "xVal -= meanImage\n",
    "xTest -= meanImage\n",
    "\n",
    "# Reshape data from channel to rows\n",
    "xTrain = np.reshape(xTrain, (xTrain.shape[0], -1))\n",
    "xVal = np.reshape(xVal, (xVal.shape[0], -1))\n",
    "xTest = np.reshape(xTest, (xTest.shape[0], -1))\n",
    "\n",
    "# Add bias dimension columns\n",
    "xTrain = np.hstack([xTrain, np.ones((xTrain.shape[0], 1))])\n",
    "xVal = np.hstack([xVal, np.ones((xVal.shape[0], 1))])\n",
    "xTest = np.hstack([xTest, np.ones((xTest.shape[0], 1))])\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Svm (object):\n",
    "    \"\"\"\" Svm classifier \"\"\"\n",
    "\n",
    "    def __init__ (self, inputDim, outputDim):\n",
    "        self.W = None\n",
    "\n",
    "        sigma =0.01\n",
    "        self.W = sigma * np.random.randn(inputDim,outputDim)\n",
    "\n",
    "\n",
    "    def calLoss (self, x, y, reg):\n",
    "\n",
    "        loss = 0.0\n",
    "        dW = np.zeros_like(self.W)\n",
    "\n",
    "        s = x.dot(self.W)\n",
    "        #Score with yi\n",
    "        s_yi = s[np.arange(x.shape[0]),y]\n",
    "        #finding the delta\n",
    "        delta = s- s_yi[:,np.newaxis]+1\n",
    "        #loss for samples\n",
    "        loss_i = np.maximum(0,delta)\n",
    "        loss_i[np.arange(x.shape[0]),y]=0\n",
    "        loss = np.sum(loss_i)/x.shape[0]\n",
    "        #Loss with regularization\n",
    "        loss += reg*np.sum(self.W*self.W)\n",
    "        #Calculating ds\n",
    "        ds = np.zeros_like(delta)\n",
    "        ds[delta > 0] = 1\n",
    "        ds[np.arange(x.shape[0]),y] = 0\n",
    "        ds[np.arange(x.shape[0]),y] = -np.sum(ds, axis=1)\n",
    "\n",
    "        dW = (1/x.shape[0]) * (x.T).dot(ds)\n",
    "        dW = dW + (2* reg* self.W)\n",
    "        #############################################################################\n",
    "        #                          END OF YOUR CODE                                 #\n",
    "        #############################################################################\n",
    "\n",
    "        return loss, dW\n",
    "\n",
    "    def train (self, x, y, lr=1e-3, reg=1e-5, iter=100, batchSize=200, verbose=False):\n",
    "\n",
    "\n",
    "        # Run stochastic gradient descent to optimize W.\n",
    "        lossHistory = []\n",
    "        for i in range(iter):\n",
    "            xBatch = None\n",
    "            yBatch = None\n",
    "\n",
    "            num_train = np.random.choice(x.shape[0], batchSize)\n",
    "            xBatch = x[num_train]\n",
    "            yBatch = y[num_train]\n",
    "            loss, dW = self.calLoss(xBatch,yBatch,reg)\n",
    "            self.W= self.W - lr * dW\n",
    "            lossHistory.append(loss)\n",
    "\n",
    "            if verbose and i % 100 == 0 and len(lossHistory) is not 0:\n",
    "                print ('Loop {0} loss {1}'.format(i, lossHistory[i]))\n",
    "\n",
    "        return lossHistory\n",
    "\n",
    "    def predict (self, x,):\n",
    "\n",
    "        yPred = np.zeros(x.shape[0])\n",
    "\n",
    "        s = x.dot(self.W)\n",
    "        yPred = np.argmax(s, axis=1)\n",
    "\n",
    "        return yPred\n",
    "\n",
    "\n",
    "    def calAccuracy (self, x, y):\n",
    "        acc = 0\n",
    "\n",
    "        yPred = self.predict(x)\n",
    "        acc = np.mean(y == yPred)*100\n",
    "\n",
    "        return acc\n",
    "numClasses = np.max(yTrain) + 1\n",
    "\n",
    "print ('Start training Svm classifier')\n",
    "\n",
    "classifier = Svm(xTrain.shape[1], numClasses)\n",
    "\n",
    "# Show weight for each class before training\n",
    "if classifier.W is not None:\n",
    "    tmpW = classifier.W[:-1, :]\n",
    "    tmpW = tmpW.reshape(32, 32, 3, 10)\n",
    "    tmpWMin, tmpWMax = np.min(tmpW), np.max(tmpW)\n",
    "    for i in range(numClasses):\n",
    "        plt.subplot(2, 5, i+1)\n",
    "        plt.title(classesName[i])\n",
    "        wPlot = 255.0 * (tmpW[:, :, :, i].squeeze() - tmpWMin) / (tmpWMax - tmpWMin)\n",
    "        plt.imshow(wPlot.astype('uint8'))\n",
    "    plt.clf()\n",
    "\n",
    "# Training classifier\n",
    "startTime = time.time()\n",
    "classifier.train(xTrain, yTrain, lr=1e-7, reg=5e4, iter=1500 ,verbose=True)\n",
    "print ('Training time: {0}'.format(time.time() - startTime))\n",
    "print ('Training acc:   {0}%'.format(classifier.calAccuracy(xTrain, yTrain)))\n",
    "print ('Validating acc: {0}%'.format(classifier.calAccuracy(xVal, yVal)))\n",
    "print ('Testing acc:    {0}%'.format(classifier.calAccuracy(xTest, yTest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac53397d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train image shape:    (49000, 32, 32, 3)\n",
      "Train label shape:    (49000,)\n",
      "Validate image shape: (1000, 32, 32, 3)\n",
      "Validate label shape: (1000,)\n",
      "Test image shape:     (10000, 32, 32, 3)\n",
      "Test label shape:     (10000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aish0\\AppData\\Local\\Temp\\ipykernel_1136\\1345919048.py:40: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Load the CIFAR10 dataset\n",
    "from keras.datasets import cifar10\n",
    "baseDir = os.path.dirname(os.path.abspath('__file__')) + '/'\n",
    "classesName = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "(xTrain, yTrain), (xTest, yTest) = cifar10.load_data()\n",
    "xVal = xTrain[49000:, :].astype(float)\n",
    "yVal = np.squeeze(yTrain[49000:, :])\n",
    "xTrain = xTrain[:49000, :].astype(float)\n",
    "yTrain = np.squeeze(yTrain[:49000, :])\n",
    "yTest = np.squeeze(yTest)\n",
    "xTest = xTest.astype(float)\n",
    "\n",
    "# Show dimension for each variable\n",
    "print ('Train image shape:    {0}'.format(xTrain.shape))\n",
    "print ('Train label shape:    {0}'.format(yTrain.shape))\n",
    "print ('Validate image shape: {0}'.format(xVal.shape))\n",
    "print ('Validate label shape: {0}'.format(yVal.shape))\n",
    "print ('Test image shape:     {0}'.format(xTest.shape))\n",
    "print ('Test label shape:     {0}'.format(yTest.shape))\n",
    "\n",
    "# Show some CIFAR10 images\n",
    "plt.subplot(221)\n",
    "plt.imshow(xTrain[0])\n",
    "plt.axis('off')\n",
    "plt.title(classesName[yTrain[0]])\n",
    "plt.subplot(222)\n",
    "plt.imshow(xTrain[1])\n",
    "plt.axis('off')\n",
    "plt.title(classesName[yTrain[1]])\n",
    "plt.subplot(223)\n",
    "plt.imshow(xVal[0])\n",
    "plt.axis('off')\n",
    "plt.title(classesName[yVal[1]])\n",
    "plt.subplot(224)\n",
    "plt.imshow(xTest[0])\n",
    "plt.axis('off')\n",
    "plt.title(classesName[yTest[0]])\n",
    "plt.savefig(baseDir+'svm0.png')\n",
    "# plt.clf()\n",
    "plt.show()\n",
    "# print(xTrain[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03c62a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49000, 32, 32, 3)\n",
      "(49000,)\n",
      "(49000, 3072)\n",
      "[ 59.  62.  63. ... 123.  92.  72.]\n",
      "(49000, 3072)\n",
      "[-0.5372549  -0.51372549 -0.50588235 ... -0.03529412 -0.27843137\n",
      " -0.43529412]\n"
     ]
    }
   ],
   "source": [
    "print(xTrain.shape)\n",
    "print(yTrain.shape)\n",
    "xTrain = np.reshape(xTrain, (xTrain.shape[0], -1)) # The -1 means that the corresponding dimension is calculated from the other given dimensions.\n",
    "xVal = np.reshape(xVal, (xVal.shape[0], -1))\n",
    "xTest = np.reshape(xTest, (xTest.shape[0], -1))\n",
    "print(xTrain.shape) \n",
    "print(xTrain[0])\n",
    "\n",
    "#Normalize \n",
    "xTrain=((xTrain/255)*2)-1 \n",
    "print(xTrain.shape)\n",
    "print(xTrain[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae450a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 9 9 ... 6 6 4]\n",
      "(3000, 3072)\n",
      "(3000,)\n"
     ]
    }
   ],
   "source": [
    "#Choosing a smaller dataset\n",
    "xTrain=xTrain[:3000,:]\n",
    "yTrain=yTrain[:3000]\n",
    "print(yTrain)\n",
    "print(xTrain.shape)\n",
    "print(yTrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6bd95b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "acc_train_svm_poly = []\n",
    "acc_test_svm_poly = []\n",
    "\n",
    "def svm_polynomial(c):\n",
    "\n",
    "    svc_polynomial = svm.SVC(probability = False, kernel = 'poly', C = c)\n",
    "    \n",
    "    \n",
    "    svc_polynomial.fit(xTrain, yTrain) \n",
    "    \n",
    "    # Find the prediction and accuracy on the training set.\n",
    "    Yhat_svc_polynomial_train = svc_polynomial.predict(xTrain)\n",
    "    acc_train = np.mean(Yhat_svc_polynomial_train == yTrain)\n",
    "    acc_train_svm_poly.append(acc_train)\n",
    "    print('Accuracy = {0:f}'.format(acc_train))\n",
    "    \n",
    "    # Find the prediction and accuracy on the test set.\n",
    "    Yhat_svc_polynomial_test = svc_polynomial.predict(xVal)\n",
    "    acc_test = np.mean(Yhat_svc_polynomial_test == yVal)\n",
    "    acc_test_svm_poly.append(acc_test)\n",
    "    print('Accuracy = {0:f}'.format(acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dd3df047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.107333\n",
      "Accuracy = 0.087000\n",
      "Accuracy = 0.107333\n",
      "Accuracy = 0.087000\n",
      "Accuracy = 0.120667\n",
      "Accuracy = 0.087000\n",
      "Accuracy = 0.272333\n",
      "Accuracy = 0.125000\n",
      "Accuracy = 0.722000\n",
      "Accuracy = 0.265000\n",
      "Accuracy = 0.963667\n",
      "Accuracy = 0.256000\n",
      "Accuracy = 0.998667\n",
      "Accuracy = 0.247000\n"
     ]
    }
   ],
   "source": [
    "c_svm_poly = [0.0001,0.001,0.01,0.1,1,10,100]\n",
    "\n",
    "\n",
    "for c in c_svm_poly:\n",
    "    svm_polynomial(c)\n",
    "\n",
    "plt.plot(c_svm_poly, acc_train_svm_poly,'.-',color='red')\n",
    "plt.plot(c_svm_poly, acc_test_svm_poly,'.-',color='orange')\n",
    "plt.xlabel('c')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Plot of accuracy vs c for training and test data\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0494d764",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aish0\\AppData\\Local\\Temp\\ipykernel_1136\\1415760643.py:7: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "plt.plot(c_svm_poly, acc_train_svm_poly,'.-',color='red')\n",
    "plt.plot(c_svm_poly, acc_test_svm_poly,'.-',color='orange')\n",
    "plt.xlabel('c')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Plot of accuracy vs c for training and test data\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4948b4af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea15532",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc1840a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfd3315",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
