{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c38852e",
   "metadata": {},
   "source": [
    "# Classification on CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5ed1d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score   \n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d449a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "864e888d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define num_class\n",
    "num_classes = 10\n",
    "\n",
    "# load dataset keras will download cifar-10 datset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9544bdb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7389da2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# (Optional)Convert class vectors to binary class matrices.\n",
    "# y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
    "# y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a1150d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "classesName = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf34ba5",
   "metadata": {},
   "source": [
    "## XGB for CIFAR 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abfc2210",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseDir =os.path.dirname(os.path.abspath('__file__')) + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd423c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\aish0\\\\OneDrive\\\\Documents\\\\College study\\\\SML\\\\Final project/'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f30120f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 train samples\n",
      "10000 test samples\n",
      "(50000, 3072) train shape\n",
      "(10000, 3072) test shape\n",
      "(50000,) train shape\n",
      "(10000,) test shape\n"
     ]
    }
   ],
   "source": [
    "# Converting the 50000 , 32*32*3 images into 50000 * 3072 arrays\n",
    "x_train = x_train.reshape(50000, 3072)\n",
    "x_test = x_test.reshape(10000, 3072)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "y_train = y_train.flatten()\n",
    "y_test = y_test.flatten()\n",
    "\n",
    "# normalize the datasets\n",
    "x_train /= 255.\n",
    "x_test /= 255.\n",
    "\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print(x_train.shape , \"train shape\")\n",
    "print(x_test.shape , \"test shape\")\n",
    "print(y_train.shape , \"train shape\")\n",
    "print(y_test.shape , \"test shape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b489f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a Xgboost model to the data\n",
    "model = xgb.XGBClassifier(gamma=0.5, learning_rate=0.01,\n",
    "                max_depth=7, n_estimators=100, \n",
    "                nthread=4, objective='multi:softmax', silent=False, \n",
    "                subsample=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0be281a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed: 67.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed: 67.7min finished\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "cv_results = cross_val_score(model, x_train, y_train, cv = 2, scoring='accuracy', n_jobs = 2, verbose = 3)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25312afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:35:27] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "\n",
      "[0.44804 0.44132]\n",
      "\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=0.5, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=7, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, nthread=4, num_parallel_tree=None,\n",
      "              objective='multi:softmax', ...)\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.53      0.53      1000\n",
      "           1       0.53      0.48      0.50      1000\n",
      "           2       0.37      0.32      0.34      1000\n",
      "           3       0.34      0.22      0.27      1000\n",
      "           4       0.35      0.38      0.37      1000\n",
      "           5       0.44      0.41      0.43      1000\n",
      "           6       0.41      0.59      0.49      1000\n",
      "           7       0.53      0.39      0.45      1000\n",
      "           8       0.54      0.63      0.58      1000\n",
      "           9       0.47      0.57      0.51      1000\n",
      "\n",
      "    accuracy                           0.45     10000\n",
      "   macro avg       0.45      0.45      0.45     10000\n",
      "weighted avg       0.45      0.45      0.45     10000\n",
      "\n",
      "\n",
      "[[529  25  57  18  38  19  26  22 204  62]\n",
      " [ 36 476  19  33  35  39  39  30  80 213]\n",
      " [ 95  37 323  68 151  63 153  50  32  28]\n",
      " [ 49  25  86 224  90 183 196  46  34  67]\n",
      " [ 54  17 148  32 382  47 200  71  22  27]\n",
      " [ 32  24  94 122 103 415  95  55  28  32]\n",
      " [ 17  35  79  54 117  42 589  24   8  35]\n",
      " [ 56  26  39  53 122  93  69 394  35 113]\n",
      " [ 79  85  22  23  17  24  24  20 627  79]\n",
      " [ 44 141  17  35  23  25  34  28  82 571]]\n",
      "\n",
      "Execution Time 12305.115726470947 seconds: \n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, verbose=True)\n",
    "\n",
    "print(); print(cv_results)    \n",
    "print(); print(model)\n",
    "\n",
    "# make predictions\n",
    "expected_y  = y_test\n",
    "predicted_y = model.predict(x_test)\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(); print(metrics.classification_report(expected_y, predicted_y))\n",
    "print(); print(metrics.confusion_matrix(expected_y, predicted_y))\n",
    "\n",
    "print()\n",
    "print(\"Execution Time %s seconds: \" % (time.time() - start_time))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a178d98",
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "No evaluation result, `eval_set` is not used during training.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19956\\2199064236.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# plot learning curves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'validation_0'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'logloss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'validation_1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'logloss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# show the legend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mevals_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1211\u001b[0m             \u001b[0mevals_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevals_result_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m             raise XGBoostError(\n\u001b[0m\u001b[0;32m   1214\u001b[0m                 \u001b[1;34m\"No evaluation result, `eval_set` is not used during training.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             )\n",
      "\u001b[1;31mXGBoostError\u001b[0m: No evaluation result, `eval_set` is not used during training."
     ]
    }
   ],
   "source": [
    "results = model.evals_result()\n",
    "# plot learning curves\n",
    "pyplot.plot(results['validation_0']['logloss'], label='train')\n",
    "pyplot.plot(results['validation_1']['logloss'], label='test')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c23206",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6e3c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6092ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
